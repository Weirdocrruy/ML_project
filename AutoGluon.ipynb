{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8c60f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be710e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>51</td>\n",
       "      <td>Private</td>\n",
       "      <td>39264</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23204</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>51662</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29590</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>326310</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18116</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>222450</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2339</td>\n",
       "      <td>40</td>\n",
       "      <td>El-Salvador</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33964</th>\n",
       "      <td>62</td>\n",
       "      <td>Private</td>\n",
       "      <td>109190</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt  ... hours-per-week  native-country   class\n",
       "6118    51   Private   39264  ...             40   United-States    >50K\n",
       "23204   58   Private   51662  ...              8   United-States   <=50K\n",
       "29590   40   Private  326310  ...             44   United-States   <=50K\n",
       "18116   37   Private  222450  ...             40     El-Salvador   <=50K\n",
       "33964   62   Private  109190  ...             40   United-States    >50K\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25bf5797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count        500\n",
      "unique         2\n",
      "top        <=50K\n",
      "freq         365\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "label = 'class'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394e25cc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"agModels-predictClass/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.7.11\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    892.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "/Users/yangzhou/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility. Expected 16 from C header, got 88 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "\t0.73\t = Validation score   (accuracy)\n",
      "\t15.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "/Users/yangzhou/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Fitting model: LightGBM ...\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.84\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t0.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.81\t = Validation score   (accuracy)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "/Users/yangzhou/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "\t0.82\t = Validation score   (accuracy)\n",
      "\t8.17s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
      "\t\tXGBoost Library (libxgboost.dylib) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): [\"dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\"]\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1074, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1032, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 121, in _fit\n",
      "    try_import_xgboost()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 104, in try_import_xgboost\n",
      "    import xgboost\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/__init__.py\", line 9, in <module>\n",
      "    from .core import DMatrix, DeviceQuantileDMatrix, Booster\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/core.py\", line 195, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/core.py\", line 186, in _load_lib\n",
      "    'Error message(s): {}\\n'.format(os_error_list))\n",
      "xgboost.core.XGBoostError: XGBoost Library (libxgboost.dylib) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): [\"dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.87\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 30.05s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictClass/\")\n"
     ]
    }
   ],
   "source": [
    "save_path = 'agModels-predictClass'  # specifies folder to store trained models\n",
    "predictor = TabularPredictor(label=label, path=save_path).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "881a1c4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv | Columns = 15 / 15 | Rows = 9769 -> 9769\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>169085</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>226203</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>Private</td>\n",
       "      <td>54260</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>Private</td>\n",
       "      <td>176262</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>Private</td>\n",
       "      <td>241185</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt  ... capital-loss  hours-per-week  native-country\n",
       "0   31            Private  169085  ...            0              20   United-States\n",
       "1   17   Self-emp-not-inc  226203  ...            0              45   United-States\n",
       "2   47            Private   54260  ...         1887              60   United-States\n",
       "3   21            Private  176262  ...            0              30   United-States\n",
       "4   17            Private  241185  ...            0              20   United-States\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "y_test = test_data[label]  # values to predict\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4c671b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.8218855563517249\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.8218855563517249,\n",
      "    \"balanced_accuracy\": 0.7209680177968016,\n",
      "    \"mcc\": 0.47748810004400455,\n",
      "    \"f1\": 0.5849236641221375,\n",
      "    \"precision\": 0.6542155816435432,\n",
      "    \"recall\": 0.5289042277825712\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      " 0        <=50K\n",
      "1        <=50K\n",
      "2        <=50K\n",
      "3        <=50K\n",
      "4        <=50K\n",
      "         ...  \n",
      "9764     <=50K\n",
      "9765     <=50K\n",
      "9766     <=50K\n",
      "9767     <=50K\n",
      "9768     <=50K\n",
      "Name: class, Length: 9769, dtype: object\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28db4f31",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.015351</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.784596</td>\n",
       "      <td>0.015351</td>\n",
       "      <td>0.005958</td>\n",
       "      <td>0.784596</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.842461</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.116827</td>\n",
       "      <td>0.111533</td>\n",
       "      <td>0.388366</td>\n",
       "      <td>0.116827</td>\n",
       "      <td>0.111533</td>\n",
       "      <td>0.388366</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.842358</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.114914</td>\n",
       "      <td>0.111875</td>\n",
       "      <td>0.391458</td>\n",
       "      <td>0.114914</td>\n",
       "      <td>0.111875</td>\n",
       "      <td>0.391458</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.834476</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.118612</td>\n",
       "      <td>0.112187</td>\n",
       "      <td>0.385980</td>\n",
       "      <td>0.118612</td>\n",
       "      <td>0.112187</td>\n",
       "      <td>0.385980</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.831917</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.118125</td>\n",
       "      <td>0.112816</td>\n",
       "      <td>0.393539</td>\n",
       "      <td>0.118125</td>\n",
       "      <td>0.112816</td>\n",
       "      <td>0.393539</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.821886</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.276344</td>\n",
       "      <td>0.127170</td>\n",
       "      <td>2.861255</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.126044</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.818610</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.088348</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>8.168602</td>\n",
       "      <td>0.088348</td>\n",
       "      <td>0.010812</td>\n",
       "      <td>8.168602</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.810523</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.140787</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>1.557076</td>\n",
       "      <td>0.140787</td>\n",
       "      <td>0.007135</td>\n",
       "      <td>1.557076</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.725970</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>15.188296</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>15.188296</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.695158</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  ...  can_infer  fit_order\n",
       "0             CatBoost    0.842461  ...       True          5\n",
       "1     RandomForestGini    0.842461  ...       True          3\n",
       "2     RandomForestEntr    0.842358  ...       True          4\n",
       "3       ExtraTreesGini    0.834476  ...       True          6\n",
       "4       ExtraTreesEntr    0.831917  ...       True          7\n",
       "5  WeightedEnsemble_L2    0.821886  ...       True         10\n",
       "6      NeuralNetFastAI    0.818610  ...       True          8\n",
       "7       NeuralNetTorch    0.810523  ...       True          9\n",
       "8       KNeighborsUnif    0.725970  ...       True          1\n",
       "9       KNeighborsDist    0.695158  ...       True          2\n",
       "\n",
       "[10 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d3ee404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;=50K</th>\n",
       "      <th>&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806976</td>\n",
       "      <td>0.193024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.890178</td>\n",
       "      <td>0.109822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.528649</td>\n",
       "      <td>0.471351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.912868</td>\n",
       "      <td>0.087132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.894868</td>\n",
       "      <td>0.105132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      <=50K      >50K\n",
       "0  0.806976  0.193024\n",
       "1  0.890178  0.109822\n",
       "2  0.528649  0.471351\n",
       "3  0.912868  0.087132\n",
       "4  0.894868  0.105132"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs = predictor.predict_proba(test_data_nolab)\n",
    "pred_probs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9119a98c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2       0.87       0.127170   2.861255                0.001261           0.126044            2       True         10\n",
      "1             CatBoost       0.85       0.005958   0.784596                0.005958           0.784596            1       True          5\n",
      "2       NeuralNetTorch       0.85       0.007135   1.557076                0.007135           1.557076            1       True          9\n",
      "3     RandomForestGini       0.84       0.111533   0.388366                0.111533           0.388366            1       True          3\n",
      "4     RandomForestEntr       0.84       0.111875   0.391458                0.111875           0.391458            1       True          4\n",
      "5      NeuralNetFastAI       0.82       0.010812   8.168602                0.010812           8.168602            1       True          8\n",
      "6       ExtraTreesGini       0.82       0.112187   0.385980                0.112187           0.385980            1       True          6\n",
      "7       ExtraTreesEntr       0.81       0.112816   0.393539                0.112816           0.393539            1       True          7\n",
      "8       KNeighborsUnif       0.73       0.002405  15.188296                0.002405          15.188296            1       True          1\n",
      "9       KNeighborsDist       0.65       0.002658   0.003321                0.002658           0.003321            1       True          2\n",
      "Number of models trained: 10\n",
      "Types of models trained:\n",
      "{'CatBoostModel', 'RFModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'KNNModel', 'NNFastAiTabularModel', 'XTModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n",
      "Plot summary of models saved to file: agModels-predictClass/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0:110: execution error: 找不到文件“某个对象”。 (-43)\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdcdaaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  binary\n",
      "AutoGluon identified the following types of features:\n",
      "('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 1 | ['sex']\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "825740ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        <=50K\n",
       "1        <=50K\n",
       "2        <=50K\n",
       "3        <=50K\n",
       "4        <=50K\n",
       "         ...  \n",
       "9764     <=50K\n",
       "9765     <=50K\n",
       "9766     <=50K\n",
       "9767     <=50K\n",
       "9768     <=50K\n",
       "Name: class, Length: 9769, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(test_data, model='CatBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf3979b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220314_132531/\"\n",
      "Presets specified: ['best_quality']\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220314_132531/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.7.11\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: class\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [' >50K', ' <=50K']\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 =  >50K, class 0 =  <=50K\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive ( >50K) vs negative ( <=50K) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    731.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.29 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 1 | ['sex']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 59.9s of the 59.9s of remaining time.\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "\t0.5196\t = Validation score   (roc_auc)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 59.86s of the 59.86s of remaining time.\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "\t0.537\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 59.85s of the 59.85s of remaining time.\n",
      "\tWill use sequential fold fitting strategy because Darwin OS does not yet support parallel folding.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 59.81s of the 59.81s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 59.8s of the 59.79s of remaining time.\n",
      "\t0.8783\t = Validation score   (roc_auc)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 59.32s of the 59.32s of remaining time.\n",
      "\t0.8847\t = Validation score   (roc_auc)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 58.85s of the 58.85s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8923\t = Validation score   (roc_auc)\n",
      "\t4.46s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 54.36s of the 54.36s of remaining time.\n",
      "\t0.8942\t = Validation score   (roc_auc)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 53.88s of the 53.88s of remaining time.\n",
      "\t0.8895\t = Validation score   (roc_auc)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 53.41s of the 53.41s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8683\t = Validation score   (roc_auc)\n",
      "\t2.03s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 51.23s of the 51.23s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\tXGBoost Library (libxgboost.dylib) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): [\"dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\"]\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1074, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1032, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 153, in _fit\n",
      "    return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 213, in _fit\n",
      "    n_repeats=n_repeats, n_repeat_start=n_repeat_start, save_folds=save_bag_folds, groups=groups, **kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 481, in _fit_folds\n",
      "    fold_fitting_strategy.after_all_folds_scheduled()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 217, in after_all_folds_scheduled\n",
      "    self._fit_fold_model(job)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 222, in _fit_fold_model\n",
      "    fold_model = self._fit(self.model_base, time_start_fold, time_limit_fold, fold_ctx, self.model_base_kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 252, in _fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **kwargs_fold)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 121, in _fit\n",
      "    try_import_xgboost()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 104, in try_import_xgboost\n",
      "    import xgboost\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/__init__.py\", line 9, in <module>\n",
      "    from .core import DMatrix, DeviceQuantileDMatrix, Booster\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/core.py\", line 195, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/core.py\", line 186, in _load_lib\n",
      "    'Error message(s): {}\\n'.format(os_error_list))\n",
      "xgboost.core.XGBoostError: XGBoost Library (libxgboost.dylib) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): [\"dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 51.2s of the 51.2s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8489\t = Validation score   (roc_auc)\n",
      "\t6.2s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 44.95s of the 44.95s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Repeating k-fold bagging: 2/20\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 44.94s of the 44.93s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8985\t = Validation score   (roc_auc)\n",
      "\t9.19s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 40.17s of the 40.17s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.884\t = Validation score   (roc_auc)\n",
      "\t3.94s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 38.18s of the 38.18s of remaining time.\n",
      "\tFitting 5 child models (S2F1 - S2F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8716\t = Validation score   (roc_auc)\n",
      "\t13.76s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Repeating k-fold bagging: 3/20\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 30.56s of the 30.56s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8982\t = Validation score   (roc_auc)\n",
      "\t13.56s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 26.16s of the 26.16s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8896\t = Validation score   (roc_auc)\n",
      "\t5.91s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 24.12s of the 24.12s of remaining time.\n",
      "\tFitting 5 child models (S3F1 - S3F5) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "\t0.8839\t = Validation score   (roc_auc)\n",
      "\t21.28s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Completed 3/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.9s of the 16.55s of remaining time.\n",
      "\t0.9091\t = Validation score   (roc_auc)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 43.95s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220314_132531/\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.901983</td>\n",
       "      <td>0.898184</td>\n",
       "      <td>0.115257</td>\n",
       "      <td>0.067629</td>\n",
       "      <td>13.555085</td>\n",
       "      <td>0.115257</td>\n",
       "      <td>0.067629</td>\n",
       "      <td>13.555085</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.899834</td>\n",
       "      <td>0.909102</td>\n",
       "      <td>3.835647</td>\n",
       "      <td>0.415602</td>\n",
       "      <td>41.609271</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.486114</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.886811</td>\n",
       "      <td>0.884739</td>\n",
       "      <td>0.115858</td>\n",
       "      <td>0.073408</td>\n",
       "      <td>0.384883</td>\n",
       "      <td>0.115858</td>\n",
       "      <td>0.073408</td>\n",
       "      <td>0.384883</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.886119</td>\n",
       "      <td>0.878316</td>\n",
       "      <td>0.117030</td>\n",
       "      <td>0.070088</td>\n",
       "      <td>0.385798</td>\n",
       "      <td>0.117030</td>\n",
       "      <td>0.070088</td>\n",
       "      <td>0.385798</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.883722</td>\n",
       "      <td>0.883917</td>\n",
       "      <td>2.324900</td>\n",
       "      <td>0.110817</td>\n",
       "      <td>21.275065</td>\n",
       "      <td>2.324900</td>\n",
       "      <td>0.110817</td>\n",
       "      <td>21.275065</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.881103</td>\n",
       "      <td>0.889488</td>\n",
       "      <td>0.115954</td>\n",
       "      <td>0.073341</td>\n",
       "      <td>0.384555</td>\n",
       "      <td>0.115954</td>\n",
       "      <td>0.073341</td>\n",
       "      <td>0.384555</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.880844</td>\n",
       "      <td>0.889599</td>\n",
       "      <td>1.275047</td>\n",
       "      <td>0.161802</td>\n",
       "      <td>5.907517</td>\n",
       "      <td>1.275047</td>\n",
       "      <td>0.161802</td>\n",
       "      <td>5.907517</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.879546</td>\n",
       "      <td>0.894206</td>\n",
       "      <td>0.117395</td>\n",
       "      <td>0.074679</td>\n",
       "      <td>0.385489</td>\n",
       "      <td>0.117395</td>\n",
       "      <td>0.074679</td>\n",
       "      <td>0.385489</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.525998</td>\n",
       "      <td>0.536956</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.514970</td>\n",
       "      <td>0.519604</td>\n",
       "      <td>0.022477</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>0.022477</td>\n",
       "      <td>0.005961</td>\n",
       "      <td>0.026419</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_test  ...  can_infer  fit_order\n",
       "0          CatBoost_BAG_L1    0.901983  ...       True          5\n",
       "1      WeightedEnsemble_L2    0.899834  ...       True         10\n",
       "2  RandomForestEntr_BAG_L1    0.886811  ...       True          4\n",
       "3  RandomForestGini_BAG_L1    0.886119  ...       True          3\n",
       "4    NeuralNetTorch_BAG_L1    0.883722  ...       True          9\n",
       "5    ExtraTreesEntr_BAG_L1    0.881103  ...       True          7\n",
       "6   NeuralNetFastAI_BAG_L1    0.880844  ...       True          8\n",
       "7    ExtraTreesGini_BAG_L1    0.879546  ...       True          6\n",
       "8    KNeighborsDist_BAG_L1    0.525998  ...       True          2\n",
       "9    KNeighborsUnif_BAG_L1    0.514970  ...       True          1\n",
       "\n",
       "[10 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_limit = 60  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'roc_auc'  # specify your evaluation metric here\n",
    "predictor = TabularPredictor(label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets='best_quality')\n",
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de81f6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of age variable: \n",
      " count    500.00000\n",
      "mean      39.65200\n",
      "std       13.52393\n",
      "min       17.00000\n",
      "25%       29.00000\n",
      "50%       38.00000\n",
      "75%       49.00000\n",
      "max       85.00000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "age_column = 'age'\n",
    "print(\"Summary of age variable: \\n\", train_data[age_column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4f746e5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"agModels-predictAge/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.7.11\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Label Column: age\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == int and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (85, 17, 39.652, 13.52393)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    735.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('object', []) : 9 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 7 | ['workclass', 'education', 'marital-status', 'occupation', 'relationship', ...]\n",
      "\t\t('int', [])       : 5 | ['fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 400, Val Rows: 100\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 59.91s of the 59.91s of remaining time.\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "\t-15.6869\t = Validation score   (root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 59.9s of the 59.9s of remaining time.\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "\t-15.1801\t = Validation score   (root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 59.89s of the 59.89s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Fitting model: LightGBM ... Training model for up to 59.86s of the 59.86s of remaining time.\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Fitting model: RandomForestMSE ... Training model for up to 59.85s of the 59.85s of remaining time.\n",
      "\t-11.6601\t = Validation score   (root_mean_squared_error)\n",
      "\t0.39s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 59.33s of the 59.33s of remaining time.\n",
      "\t-11.7993\t = Validation score   (root_mean_squared_error)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 58.63s of the 58.63s of remaining time.\n",
      "\t-11.3541\t = Validation score   (root_mean_squared_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 58.23s of the 58.23s of remaining time.\n",
      "\t-12.0733\t = Validation score   (root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 57.76s of the 57.76s of remaining time.\n",
      "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
      "\t\tXGBoost Library (libxgboost.dylib) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): [\"dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\"]\n",
      "\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1074, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, **model_fit_kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1032, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, **model_fit_kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/tabular/models/xgboost/xgboost_model.py\", line 121, in _fit\n",
      "    try_import_xgboost()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 104, in try_import_xgboost\n",
      "    import xgboost\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/__init__.py\", line 9, in <module>\n",
      "    from .core import DMatrix, DeviceQuantileDMatrix, Booster\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/core.py\", line 195, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/core.py\", line 186, in _load_lib\n",
      "    'Error message(s): {}\\n'.format(os_error_list))\n",
      "xgboost.core.XGBoostError: XGBoost Library (libxgboost.dylib) could not be loaded.\n",
      "Likely causes:\n",
      "  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n",
      "  * You are running 32-bit Python on a 64-bit OS\n",
      "Error message(s): [\"dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\"]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: NeuralNetTorch ... Training model for up to 57.74s of the 57.74s of remaining time.\n",
      "\t-11.9954\t = Validation score   (root_mean_squared_error)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 56.69s of the 56.69s of remaining time.\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.91s of the 56.4s of remaining time.\n",
      "\t-11.2431\t = Validation score   (root_mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3.71s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"agModels-predictAge/\")\n",
      "Evaluation: root_mean_squared_error on test data: -10.572139321817517\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -10.572139321817517,\n",
      "    \"mean_squared_error\": -111.77012983992672,\n",
      "    \"mean_absolute_error\": -8.352588190248012,\n",
      "    \"r2\": 0.4025669592145974,\n",
      "    \"pearsonr\": 0.6365220570074619,\n",
      "    \"median_absolute_error\": -7.009181976318359\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "predictor_age = TabularPredictor(label=age_column, path=\"agModels-predictAge\").fit(train_data, time_limit=60)\n",
    "performance = predictor_age.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78803f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-10.572139</td>\n",
       "      <td>-11.243110</td>\n",
       "      <td>0.370990</td>\n",
       "      <td>0.125822</td>\n",
       "      <td>1.875892</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.101652</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-10.646028</td>\n",
       "      <td>-11.354060</td>\n",
       "      <td>0.118690</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.278907</td>\n",
       "      <td>0.118690</td>\n",
       "      <td>0.108943</td>\n",
       "      <td>0.278907</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-10.755027</td>\n",
       "      <td>-11.660125</td>\n",
       "      <td>0.115939</td>\n",
       "      <td>0.112646</td>\n",
       "      <td>0.388159</td>\n",
       "      <td>0.115939</td>\n",
       "      <td>0.112646</td>\n",
       "      <td>0.388159</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-10.780312</td>\n",
       "      <td>-11.799279</td>\n",
       "      <td>0.016711</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.687825</td>\n",
       "      <td>0.016711</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.687825</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-11.225699</td>\n",
       "      <td>-12.073282</td>\n",
       "      <td>0.085201</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.447046</td>\n",
       "      <td>0.085201</td>\n",
       "      <td>0.007624</td>\n",
       "      <td>0.447046</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-11.448391</td>\n",
       "      <td>-11.995427</td>\n",
       "      <td>0.139039</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>1.044895</td>\n",
       "      <td>0.139039</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>1.044895</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-14.902058</td>\n",
       "      <td>-15.686937</td>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.021228</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-15.771259</td>\n",
       "      <td>-15.180150</td>\n",
       "      <td>0.025483</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.025483</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_test  ...  can_infer  fit_order\n",
       "0  WeightedEnsemble_L2  -10.572139  ...       True          8\n",
       "1        ExtraTreesMSE  -10.646028  ...       True          5\n",
       "2      RandomForestMSE  -10.755027  ...       True          3\n",
       "3             CatBoost  -10.780312  ...       True          4\n",
       "4      NeuralNetFastAI  -11.225699  ...       True          6\n",
       "5       NeuralNetTorch  -11.448391  ...       True          7\n",
       "6       KNeighborsUnif  -14.902058  ...       True          1\n",
       "7       KNeighborsDist  -15.771259  ...       True          2\n",
       "\n",
       "[8 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_age.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8cae3",
   "metadata": {},
   "source": [
    "- 深度预测表中的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef0fca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age workclass  fnlwgt      education  education-num  \\\n",
      "6118    51   Private   39264   Some-college             10   \n",
      "23204   58   Private   51662           10th              6   \n",
      "29590   40   Private  326310   Some-college             10   \n",
      "18116   37   Private  222450        HS-grad              9   \n",
      "33964   62   Private  109190      Bachelors             13   \n",
      "\n",
      "            marital-status        occupation    relationship    race      sex  \\\n",
      "6118    Married-civ-spouse   Exec-managerial            Wife   White   Female   \n",
      "23204   Married-civ-spouse     Other-service            Wife   White   Female   \n",
      "29590   Married-civ-spouse      Craft-repair         Husband   White     Male   \n",
      "18116        Never-married             Sales   Not-in-family   White     Male   \n",
      "33964   Married-civ-spouse   Exec-managerial         Husband   White     Male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week  native-country   class  \n",
      "6118              0             0              40   United-States    >50K  \n",
      "23204             0             0               8   United-States   <=50K  \n",
      "29590             0             0              44   United-States   <=50K  \n",
      "18116             0          2339              40     El-Salvador   <=50K  \n",
      "33964         15024             0              40   United-States    >50K  \n",
      "Summary of occupation column: \n",
      " count                  500\n",
      "unique                  15\n",
      "top        Exec-managerial\n",
      "freq                    77\n",
      "Name: occupation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "print(train_data.head())\n",
    "\n",
    "label = 'occupation'\n",
    "print(\"Summary of occupation column: \\n\", train_data['occupation'].describe())\n",
    "\n",
    "new_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_data = new_data[5000:].copy()  # this should be separate data in your applications\n",
    "y_test = test_data[label]\n",
    "test_data_nolabel = test_data.drop(columns=[label])  # delete label column\n",
    "val_data = new_data[:5000].copy()\n",
    "\n",
    "metric = 'accuracy' # we specify eval-metric just for demo (unnecessary as it's the default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a782db67",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220315_015030/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220315_015030/\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.7.11\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    500\n",
      "Train Data Columns: 14\n",
      "Tuning Data Rows:    5000\n",
      "Tuning Data Columns: 14\n",
      "Label Column: occupation\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 15) unique label values:  [' Exec-managerial', ' Other-service', ' Craft-repair', ' Sales', ' Prof-specialty', ' Protective-serv', ' ?', ' Adm-clerical', ' Machine-op-inspct', ' Tech-support']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 12 out of 15 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.978\n",
      "Train Data Class Count: 12\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    834.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.11 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('object', []) : 8 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "\t\t('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "\t\t('int', ['bool']) : 2 | ['sex', 'class']\n",
      "\t0.1s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.3 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 2 L1 models ...\n",
      "Hyperparameter tuning model: LightGBM ... Tuning model for up to 53.95s of the 119.88s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a886f6fc3f34869b40dedd87e4d9395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 93, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 110, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 101, in _load_lib\n",
      "    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 442, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 364, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 40, in model_trial\n",
      "    reporter=None,\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 82, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 99, in try_import_lightgbm\n",
      "    \"Please try 'brew install libomp'. Detailed info: {}\".format(str(e)))\n",
      "ImportError: `import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 93, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 110, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 101, in _load_lib\n",
      "    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 442, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 364, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 40, in model_trial\n",
      "    reporter=None,\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 82, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 99, in try_import_lightgbm\n",
      "    \"Please try 'brew install libomp'. Detailed info: {}\".format(str(e)))\n",
      "ImportError: `import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 93, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 110, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 101, in _load_lib\n",
      "    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 442, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 364, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 40, in model_trial\n",
      "    reporter=None,\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 82, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 99, in try_import_lightgbm\n",
      "    \"Please try 'brew install libomp'. Detailed info: {}\".format(str(e)))\n",
      "ImportError: `import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 93, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 110, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 101, in _load_lib\n",
      "    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 442, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 364, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 40, in model_trial\n",
      "    reporter=None,\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 82, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 99, in try_import_lightgbm\n",
      "    \"Please try 'brew install libomp'. Detailed info: {}\".format(str(e)))\n",
      "ImportError: `import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "`import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 93, in try_import_lightgbm\n",
      "    import lightgbm\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/__init__.py\", line 8, in <module>\n",
      "    from .basic import Booster, Dataset, Sequence, register_logger\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 110, in <module>\n",
      "    _LIB = _load_lib()\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/basic.py\", line 101, in _load_lib\n",
      "    lib = ctypes.cdll.LoadLibrary(lib_path[0])\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 442, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"/Users/yangzhou/opt/anaconda3/lib/python3.7/ctypes/__init__.py\", line 364, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "OSError: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 40, in model_trial\n",
      "    reporter=None,\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/model_trial.py\", line 73, in fit_and_save_model\n",
      "    model.fit(**fit_args, time_limit=time_left, reporter=reporter)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 577, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/tabular/models/lgb/lgb_model.py\", line 82, in _fit\n",
      "    try_import_lightgbm()  # raise helpful error message if LightGBM isn't installed\n",
      "  File \"/Users/yangzhou/.local/lib/python3.7/site-packages/autogluon/core/utils/try_import.py\", line 99, in try_import_lightgbm\n",
      "    \"Please try 'brew install libomp'. Detailed info: {}\".format(str(e)))\n",
      "ImportError: `import lightgbm` failed. If you are using Mac OSX, Please try 'brew install libomp'. Detailed info: dlopen(/Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 0x0006): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n",
      "  Referenced from: /Users/yangzhou/.local/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n",
      "  Reason: tried: '/usr/local/opt/libomp/lib/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)\n",
      "Warning: Detected a large trial failure rate: 5/5 attempted trials failed (100.0%)! Stopping HPO early due to reaching failure threshold (80.0%).\n",
      "\tFailures may be caused by invalid configurations within the provided search space.\n",
      "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 53.95s of the 119.29s of remaining time.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6da6b93b874dbf99314fc253dc2e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: NeuralNetTorch/T1 ...\n",
      "\t0.269\t = Validation score   (accuracy)\n",
      "\t4.49s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/T2 ...\n",
      "\t0.316\t = Validation score   (accuracy)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/T3 ...\n",
      "\t0.2983\t = Validation score   (accuracy)\n",
      "\t1.36s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/T4 ...\n",
      "\t0.3371\t = Validation score   (accuracy)\n",
      "\t2.82s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitted model: NeuralNetTorch/T5 ...\n",
      "\t0.3258\t = Validation score   (accuracy)\n",
      "\t3.68s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.88s of the 103.95s of remaining time.\n",
      "\t0.351\t = Validation score   (accuracy)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 16.49s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220315_015030/\")\n"
     ]
    }
   ],
   "source": [
    "import autogluon.core as ag\n",
    "\n",
    "nn_options = {  # specifies non-default hyperparameter values for neural network models\n",
    "    'num_epochs': 10,  # number of training epochs (controls training time of NN models)\n",
    "    'learning_rate': ag.space.Real(1e-4, 1e-2, default=5e-4, log=True),  # learning rate used in training (real-valued hyperparameter searched on log-scale)\n",
    "    'activation': ag.space.Categorical('relu', 'softrelu', 'tanh'),  # activation function used in NN (categorical hyperparameter, default = first entry)\n",
    "    'dropout_prob': ag.space.Real(0.0, 0.5, default=0.1),  # dropout probability (real-valued hyperparameter)\n",
    "}\n",
    "\n",
    "gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "    'num_leaves': ag.space.Int(lower=26, upper=66, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "}\n",
    "\n",
    "hyperparameters = {  # hyperparameters of each model type\n",
    "                   'GBM': gbm_options,\n",
    "                   'NN_TORCH': nn_options,  # NOTE: comment this line out if you get errors on Mac OSX\n",
    "                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "time_limit = 2*60  # train various models for ~2 min\n",
    "num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "    'num_trials': num_trials,\n",
    "    'scheduler' : 'local',\n",
    "    'searcher': search_strategy,\n",
    "}\n",
    "\n",
    "predictor = TabularPredictor(label=label, eval_metric=metric).fit(\n",
    "    train_data, tuning_data=val_data, time_limit=time_limit,\n",
    "    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56821c39",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:   [' Exec-managerial', ' Exec-managerial', ' Craft-repair', ' Other-service', ' Adm-clerical']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: accuracy on test data: 0.33424197945061856\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"accuracy\": 0.33424197945061856\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data_nolabel)\n",
    "print(\"Predictions:  \", list(y_pred)[:5])\n",
    "perf = predictor.evaluate(test_data, auxiliary_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435a1145",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0  WeightedEnsemble_L2   0.351035       0.577585  12.883433                0.001607           0.432759            2       True          6\n",
      "1    NeuralNetTorch/T4   0.337092       0.185139   2.822023                0.185139           2.822023            1       True          4\n",
      "2    NeuralNetTorch/T5   0.325815       0.233860   3.684330                0.233860           3.684330            1       True          5\n",
      "3    NeuralNetTorch/T2   0.315973       0.094650   1.456319                0.094650           1.456319            1       True          2\n",
      "4    NeuralNetTorch/T3   0.298339       0.137883   1.360654                0.137883           1.360654            1       True          3\n",
      "5    NeuralNetTorch/T1   0.269018       0.062329   4.488002                0.062329           4.488002            1       True          1\n",
      "Number of models trained: 6\n",
      "Types of models trained:\n",
      "{'WeightedEnsembleModel', 'TabularNeuralNetTorchModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  : 6 | ['workclass', 'education', 'marital-status', 'relationship', 'race', ...]\n",
      "('int', [])       : 6 | ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', ...]\n",
      "('int', ['bool']) : 2 | ['sex', 'class']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20220315_015030/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0:123: execution error: 找不到文件“某个对象”。 (-43)\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary(show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90beb37",
   "metadata": {},
   "source": [
    "### Multimodal Data Table:Tablular,text,and Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5354575",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = './ag_petfinder_tutorial'\n",
    "zip_file = 'https://automl-mm-bench.s3.amazonaws.com/petfinder_kaggle.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.core.utils.loaders import load_zip\n",
    "load_zip.unzip(zip_file,unzip_dir=download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201dc242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir(download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = download_dir+'/petfinder_processed'\n",
    "os.listdir(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e09422",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dataset_path+'/train_images')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a543475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(f'{dataset_path}/train.csv',index_col=0)\n",
    "test_data = pd.read_csv(f'{dataset_path}/dev.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911970b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多分类标签\n",
    "label = 'AdoptionSpeed'\n",
    "image_col = 'Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16466f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像列\n",
    "train_data[image_col].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702eca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目前只支持每行一个图像\n",
    "train_data[image_col] = train_data[image_col].apply(lambda ele:ele.split(';')[0])\n",
    "test_data[image_col] = test_data[image_col].apply(lambda ele:ele.split(';')[0])\n",
    "train_data[image_col].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新路径来指向磁盘上的正确位置\n",
    "def path_expander(path,base_folder):\n",
    "    path_l = path.split(';')\n",
    "    return ';'.join([os.path.abspath(os.join(base_folder,path)) for path in path_l])\n",
    "train_data[image_col] = train_data[image_col].apply(lambda ele:path_expander(ele,base_folder=dataset_path))\n",
    "test_data[image_col] = test_data[image_col].apply(lambda ele:path_expander(ele,base_folder=dataset_path))\n",
    "train_data[image_col].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff488d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看每行数据\n",
    "example_row = train_data.iloc[1]\n",
    "example_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4726a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本信息\n",
    "example_row['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片信息\n",
    "example_image = example_row['Images']\n",
    "from IPython.display import Image,display\n",
    "pil_img = Image(filename=example_image)\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选500条数据进行训练\n",
    "train_data = train_data.sample(500,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9595f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过构造一个来自训练数据的FeatureMetadata对象来推断特性类型\n",
    "from autogluon.tabular import FeatureMetadata\n",
    "feature_metadata = FeatureMetadata.from_df(train_data)\n",
    "print(feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为了利用图像，告诉哪一列包含图像路径，通过FeatureMetadata对象并向图像列添加'image_path'特殊类型来实现\n",
    "feature_metadata = feature_metadata.add_special_types({image_col:['image_path']})\n",
    "print(feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7877f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定超参数\n",
    "# AutoGluon有一个默认设置，可以很好地用于多模态数据集\n",
    "from autogluon.tabular.configs.hyperparameter_configs import get_hyperparameter_config\n",
    "hyperparameters = get_hyperparameter_config('multimodal')\n",
    "hyperparameters\n",
    "# 这个超参数配置将训练各种列表模型，以及微调一个Electra BERT文本模型和一个ResNet图像模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在数据集上训练一个TabularPredicto，将同时利用表格、文本和图像特性\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=label).fit(train_data = train_data\n",
    "                                             ,hyperparameters=hyperparameters\n",
    "                                             ,feature_metadata=feature_metadata\n",
    "                                             ,time_limit=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db16d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在拟合之后，查看各种模型的表现\n",
    "leaderboard = predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51295438",
   "metadata": {},
   "source": [
    "#### 多模态数据表：结合BERT/Transformers和经典表格模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18735993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理包含文本/数字和分类列的多模式表格数据\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import random\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c418e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产品情绪分析数据集\n",
    "!mkdir -p product_sentiment_machine_hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38c425",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_size = 2000  # for quick demo, try setting to larger values\n",
    "feature_columns = ['Product_Description', 'Product_Type']\n",
    "label = 'Sentiment'\n",
    "\n",
    "train_df = pd.read_csv('product_sentiment_machine_hack/train.csv', index_col=0).sample(2000, random_state=123)\n",
    "dev_df = pd.read_csv('product_sentiment_machine_hack/dev.csv', index_col=0)\n",
    "test_df = pd.read_csv('product_sentiment_machine_hack/test.csv', index_col=0)\n",
    "\n",
    "train_df = train_df[feature_columns + [label]]\n",
    "dev_df = dev_df[feature_columns + [label]]\n",
    "test_df = test_df[feature_columns]\n",
    "print('Number of training samples:', len(train_df))\n",
    "print('Number of dev samples:', len(dev_df))\n",
    "print('Number of test samples:', len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aea1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集有两个特征及标签\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3337a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要使用TextPredictor内部的模型TabularPredictor，必须在AutoGluon表格中指定\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label='Sentiment',path='ag_tabular_product_sentiment_multimodal')\n",
    "predictor.fit(train_df,hyperparameters='multimodal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b107801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用Stack Ensemble 提高性能\n",
    "predictor.fit(train_df,hyperparameters='multimodal',num_bag_folds=5,num_stack_levels=1)\n",
    "# num_stack_levels(多少层叠层)和num_bag_folds(在袋装期间将数据分成多少折叠)\n",
    "# 或者使用\n",
    "predictor.fit(train_df,hyperparameters='multimodal',presets='best_quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f813ed",
   "metadata": {},
   "source": [
    "#### 预测表中的多个列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0676c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset,TabularPredictor\n",
    "from autogluon.common.utils.utils import setup_outputdir\n",
    "from autogluon.core.utils.loaders import load_pkl\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个自定义MUltilabelPredictor类来管理一组TabularPredictor对象，每个标签一个\n",
    "class MultilabelPredictor():\n",
    "    \"\"\" Tabular Predictor for predicting multiple columns in table.\n",
    "        Creates multiple TabularPredictor objects which you can also use individually.\n",
    "        You can access the TabularPredictor for a particular label via: `multilabel_predictor.get_predictor(label_i)`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        labels : List[str]\n",
    "            The ith element of this list is the column (i.e. `label`) predicted by the ith TabularPredictor stored in this object.\n",
    "        path : str, default = None\n",
    "            Path to directory where models and intermediate outputs should be saved.\n",
    "            If unspecified, a time-stamped folder called \"AutogluonModels/ag-[TIMESTAMP]\" will be created in the working directory to store all models.\n",
    "            Note: To call `fit()` twice and save all results of each fit, you must specify different `path` locations or don't specify `path` at all.\n",
    "            Otherwise files from first `fit()` will be overwritten by second `fit()`.\n",
    "            Caution: when predicting many labels, this directory may grow large as it needs to store many TabularPredictors.\n",
    "        problem_types : List[str], default = None\n",
    "            The ith element is the `problem_type` for the ith TabularPredictor stored in this object.\n",
    "        eval_metrics : List[str], default = None\n",
    "            The ith element is the `eval_metric` for the ith TabularPredictor stored in this object.\n",
    "        consider_labels_correlation : bool, default = True\n",
    "            Whether the predictions of multiple labels should account for label correlations or predict each label independently of the others.\n",
    "            If True, the ordering of `labels` may affect resulting accuracy as each label is predicted conditional on the previous labels appearing earlier in this list (i.e. in an auto-regressive fashion).\n",
    "            Set to False if during inference you may want to individually use just the ith TabularPredictor without predicting all the other labels.\n",
    "        kwargs :\n",
    "            Arguments passed into the initialization of each TabularPredictor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=True, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        \"\"\" Fits a separate TabularPredictor to predict each of the labels.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            train_data, tuning_data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                See documentation for `TabularPredictor.fit()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `fit()` call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        \"\"\" Returns DataFrame with label columns containing predictions for each label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. If label columns are present in this data, they will be ignored. See documentation for `TabularPredictor.predict()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the predict() call for each TabularPredictor.\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `predict_proba()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to make predictions for. See documentation for `TabularPredictor.predict()` and `TabularPredictor.predict_proba()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `predict_proba()` call for each TabularPredictor (also passed into a `predict()` call).\n",
    "        \"\"\"\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        \"\"\" Returns dict where each key is a label and the corresponding value is the `evaluate()` output for just that label.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            data : str or autogluon.tabular.TabularDataset or pd.DataFrame\n",
    "                Data to evalate predictions of all labels for, must contain all labels as columns. See documentation for `TabularPredictor.evaluate()`.\n",
    "            kwargs :\n",
    "                Arguments passed into the `evaluate()` call for each TabularPredictor (also passed into the `predict()` call).\n",
    "        \"\"\"\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        \"\"\" Load MultilabelPredictor from disk `path` previously specified when creating this MultilabelPredictor. \"\"\"\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        \"\"\" Returns TabularPredictor which is used to predict this label. \"\"\"\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f903e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv')\n",
    "subsample_size = 500  # subsample subset of data for faster demo, try setting this to much larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9a8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['education-num','education','class']\n",
    "problem_types = ['regression','multiclass','binary']\n",
    "eval_metrics = ['mean_absolute_error','accuracy','accuracy']\n",
    "save_path = 'agModels-predictEducationClass'\n",
    "time_limit = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2eacfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=labels,problem_types=problem_types,eval_metrics=eval_metrics,path=save_path)\n",
    "multi_predictor.fit(train_data,time_limit=time_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测和评估\n",
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv')\n",
    "test_datat = test_data.sample(n=subsample_size,random_state=0)\n",
    "test_data_nolab = test_data.drop(columns=labels)\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366bb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predictor = Multilabelpredictor.load(save_path)\n",
    "predictions = multi_predictor.predict(test_data_nolab)\n",
    "print('Predictions: \\n',predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0030385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果新数据包含基本事实标签，还可以评估预测的性能\n",
    "evaluations = multi_predictor.evaluate(test_data)\n",
    "print(evaluations)\n",
    "print('Evaluates using metrics:',multi_predictor.eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ecdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 访问一个标签的预测\n",
    "predictor_class = multi_predictor.get_predictor('class')\n",
    "predictor_class.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45023046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb316048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e065ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30b710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
